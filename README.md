## Translation with Transformers

### Course project in EDAN30 VT2024

#### Authors: Pernilla Åström, Alice Tottie and Maja Rygård

This project is based on a lab from Pierre Nugues and Marcus Klang:
https://github.com/pnugues/edan20/blob/master/labs_2023/6-translation_transformer_shared_embs.ipynb 

The code is heavily inspired from The Annotated Transformer (Attention is all you Need).
http://nlp.seas.harvard.edu/annotated-transformer/#encoder-self-attention

The first version is our submission for the course and the second version is a revised version that takes into account suggestions from supervisors.
