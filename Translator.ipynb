{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vårt projekt\n",
    "\n",
    "from typing import Tuple\n",
    "\n",
    "from torch import Tensor\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Transformer\n",
    "from torch.utils.data import dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "import random\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.1\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install sentencepiece\n",
    "# pip install tqdm\n",
    "#conda install pytorch torchvision torchaudio -c pytorch\n",
    "#python -m pip uninstall pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as spm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10c78d870>"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(1234)\n",
    "np.random.seed(1234)\n",
    "torch.manual_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "\n",
    "else:\n",
    "    device = 'cpu'\n",
    "DEVICE = torch.device(device)\n",
    "DEVICE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alice paths\n",
    "data_path = '/Users/alicetottie/Downloads/projekt_data/train_paracrawl.en'\n",
    "data_path_2 = '/Users/alicetottie/Downloads/projekt_data/train_paracrawl.sv'\n",
    "\n",
    "#Maja paths\n",
    "# data_path = '/Users/majarygard/Documents/LTH/Projekt i Data/train_paracrawl.en'\n",
    "# data_path_2 = '/Users/majarygard/Documents/LTH/Projekt i Data/train_paracrawl.sv'\n",
    "\n",
    "#Pernilla paths\n",
    "#data_path = 'C:\\\\Users\\\\nilla\\\\Plugg\\\\project-data\\\\train_paracrawl.en\\\\train_paracrawl.en'\n",
    "#data_path_2 = 'C:\\\\Users\\\\nilla\\\\Plugg\\\\project-data\\\\train_paracrawl.sv\\\\train_paracrawl.sv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.read().split(\"\\n\")\n",
    "\n",
    "with open(data_path_2, \"r\", encoding=\"utf-8\") as f:\n",
    "    lines2 = f.read().split(\"\\n\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4960283"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lines)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4960283"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lines2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 1000\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "\n",
    "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
    "    input_text= line.split(\"\\t\")\n",
    "    input_texts.append(input_text)\n",
    "\n",
    "with open(\"input_texts.txt\", \"w\", encoding='utf-8') as f:\n",
    "    for input_text in input_texts:\n",
    "        f.write('\\t'.join(input_text) + '\\n')\n",
    "    \n",
    "for line in lines2[: min(num_samples, len(lines2) - 1)]:\n",
    "    target_text= line.split(\"\\t\")\n",
    "    target_texts.append(target_text)  \n",
    "\n",
    "with open(\"input_texts.txt\", \"a\", encoding='utf-8') as f:\n",
    "    for target_text in target_texts:\n",
    "        f.write('\\t'.join(target_text) + '\\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\" This is my third course and I bought this concept a long time ago.']"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_texts[500]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\" Det här är min tredje kurs och jag har köpt det hela för länge sedan.']"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_texts[500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_PERCENTAGE = 0.8\n",
    "train_val = int(TRAIN_PERCENTAGE * num_samples)\n",
    "train_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pairs = list(zip(input_texts, target_texts))\n",
    "random.shuffle(text_pairs)\n",
    "input_texts, target_texts = zip(*text_pairs)\n",
    "input_texts, target_texts = list(input_texts), list(target_texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_texts = input_texts[:train_val]\n",
    "train_target_texts = target_texts[:train_val]\n",
    "\n",
    "val_input_texts = input_texts[train_val:]\n",
    "val_target_texts = target_texts[train_val:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', '▁This', '▁is', '▁a', '▁test', '</s>']\n",
      "[1, 1221, 120, 6, 2384, 2]\n",
      "This is a test\n",
      "honomill terte\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(178) LOG(INFO) Running command: --input=input_texts.txt --model_prefix=m --vocab_size=4000 --model_type=bpe --pad_id=3\n",
      "sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: input_texts.txt\n",
      "  input_format: \n",
      "  model_prefix: m\n",
      "  model_type: BPE\n",
      "  vocab_size: 4000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  seed_sentencepieces_file: \n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: 3\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(353) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(185) LOG(INFO) Loading corpus: input_texts.txt\n",
      "trainer_interface.cc(409) LOG(INFO) Loaded all 2000 sentences\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <pad>\n",
      "trainer_interface.cc(430) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(539) LOG(INFO) all chars count=219191\n",
      "trainer_interface.cc(550) LOG(INFO) Done: 99.9526% characters are covered.\n",
      "trainer_interface.cc(560) LOG(INFO) Alphabet size=107\n",
      "trainer_interface.cc(561) LOG(INFO) Final character coverage=0.999526\n",
      "trainer_interface.cc(592) LOG(INFO) Done! preprocessed 2000 sentences.\n",
      "trainer_interface.cc(598) LOG(INFO) Tokenizing input sentences with whitespace: 2000\n",
      "trainer_interface.cc(609) LOG(INFO) Done! 12217\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2839 min_freq=7\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1156 size=20 all=2739 active=1812 piece=on\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=623 size=40 all=3662 active=2735 piece=ör\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=497 size=60 all=4456 active=3529 piece=▁n\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=355 size=80 all=5315 active=4388 piece=▁för\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=282 size=100 all=5945 active=5018 piece=▁r\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=282 min_freq=26\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=224 size=120 all=6537 active=1569 piece=▁B\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=189 size=140 all=7087 active=2119 piece=▁det\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=163 size=160 all=7710 active=2742 piece=ud\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=141 size=180 all=8463 active=3495 piece=▁den\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=127 size=200 all=9000 active=4032 piece=▁V\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=127 min_freq=21\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=104 size=220 all=9386 active=1354 piece=\":\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=89 size=240 all=9822 active=1790 piece=ve\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=79 size=260 all=10137 active=2105 piece=eb\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=72 size=280 all=10524 active=2492 piece=▁res\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=66 size=300 all=10918 active=2886 piece=▁are\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=65 min_freq=19\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=62 size=320 all=11253 active=1334 piece=:3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=58 size=340 all=11476 active=1557 piece=▁Jesus\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=54 size=360 all=11790 active=1871 piece=▁9\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=51 size=380 all=12023 active=2104 piece=cl\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=49 size=400 all=12311 active=2392 piece=▁any\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=48 min_freq=16\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=46 size=420 all=12559 active=1247 piece=ile\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=44 size=440 all=12814 active=1502 piece=ions\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=41 size=460 all=13018 active=1706 piece=ake\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=40 size=480 all=13207 active=1895 piece=▁produ\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=37 size=500 all=13303 active=1991 piece=▁7\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=37 min_freq=15\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=36 size=520 all=13557 active=1246 piece=▁Th\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=35 size=540 all=13694 active=1383 piece=▁will\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=33 size=560 all=13853 active=1542 piece=7)\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=32 size=580 all=14053 active=1742 piece=▁fil\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=31 size=600 all=14184 active=1873 piece=ater\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=31 min_freq=13\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=30 size=620 all=14346 active=1146 piece=arn\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=30 size=640 all=14518 active=1318 piece=▁efter\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=29 size=660 all=14733 active=1533 piece=ations\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=28 size=680 all=14913 active=1713 piece=▁gör\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=27 size=700 all=15026 active=1826 piece=▁every\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=26 min_freq=12\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=26 size=720 all=15194 active=1166 piece=▁Con\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=25 size=740 all=15339 active=1311 piece=ser\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=25 size=760 all=15445 active=1417 piece=formation\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=24 size=780 all=15589 active=1561 piece=cript\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=23 size=800 all=15676 active=1648 piece=▁ro\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=23 min_freq=11\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=22 size=820 all=15783 active=1097 piece=we\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=22 size=840 all=15905 active=1219 piece=▁Dav\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=21 size=860 all=16068 active=1382 piece=red\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=21 size=880 all=16166 active=1480 piece=heter\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=20 size=900 all=16237 active=1551 piece=ket\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=20 min_freq=10\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=20 size=920 all=16346 active=1103 piece=▁str\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=19 size=940 all=16424 active=1181 piece=bb\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=19 size=960 all=16663 active=1420 piece=▁vä\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=19 size=980 all=16733 active=1490 piece=▁bästa\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=18 size=1000 all=16925 active=1682 piece=▁Ar\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=18 min_freq=9\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=18 size=1020 all=17015 active=1083 piece=▁(1.8\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=17 size=1040 all=17085 active=1153 piece=act\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=17 size=1060 all=17228 active=1296 piece=▁Ab\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=17 size=1080 all=17315 active=1383 piece=Matte\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=17 size=1100 all=17337 active=1405 piece=▁person\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=17 min_freq=9\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16 size=1120 all=17456 active=1116 piece=▁ge\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16 size=1140 all=17552 active=1212 piece=▁mat\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16 size=1160 all=17614 active=1274 piece=▁hand\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15 size=1180 all=17694 active=1354 piece=åt\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15 size=1200 all=17824 active=1484 piece=iety\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=15 min_freq=8\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15 size=1220 all=17894 active=1068 piece=▁fant\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15 size=1240 all=17914 active=1088 piece=▁mellan\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14 size=1260 all=18053 active=1227 piece=ute\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14 size=1280 all=18136 active=1310 piece=▁Som\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14 size=1300 all=18217 active=1391 piece=▁well\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=14 min_freq=8\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14 size=1320 all=18214 active=998 piece=▁konverter\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13 size=1340 all=18338 active=1122 piece=jur\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13 size=1360 all=18450 active=1234 piece=▁kö\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13 size=1380 all=18546 active=1330 piece=▁fol\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13 size=1400 all=18603 active"
     ]
    }
   ],
   "source": [
    "spm.SentencePieceTrainer.train('--input=input_texts.txt --model_prefix=m --vocab_size=4000 --model_type=bpe --pad_id=3')\n",
    "\n",
    "# makes segmenter instance and loads the model file (m.model)\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load('m.model')\n",
    "\n",
    "sp.SetEncodeExtraOptions(\"bos:eos\")\n",
    "sp.SetDecodeExtraOptions(\"bos:eos\")\n",
    "\n",
    "# encode: text => id\n",
    "print(sp.encode_as_pieces('This is a test'))\n",
    "print(sp.encode_as_ids('This is a test'))\n",
    "\n",
    "# decode: id => text\n",
    "print(sp.decode_pieces(['▁This', '▁is', '▁a', '▁t', 'est']))\n",
    "print(sp.decode_ids([1, 665, 64, 5, 4, 134, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=1387 piece=▁jord\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=13 min_freq=7\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13 size=1420 all=18619 active=1013 piece=Lukasev\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12 size=1440 all=18665 active=1059 piece=:17\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12 size=1460 all=18781 active=1175 piece=▁50\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12 size=1480 all=18844 active=1238 piece=▁död\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12 size=1500 all=18901 active=1295 piece=▁(142\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=12 min_freq=7\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12 size=1520 all=18907 active=1007 piece=▁många\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=1540 all=18909 active=1009 piece=IT\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=1560 all=19013 active=1113 piece=ret\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=1580 all=19098 active=1198 piece=line\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=1600 all=19142 active=1242 piece=▁pop\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=11 min_freq=7\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=1620 all=19199 active=1057 piece=▁prof\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=1640 all=19210 active=1068 piece=▁bättre\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=1660 all=19246 active=1104 piece=ej\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=1680 all=19349 active=1207 piece=ris\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=1700 all=19423 active=1281 piece=ella\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=10 min_freq=6\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=1720 all=19481 active=1054 piece=▁cho\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=1740 all=19529 active=1102 piece=▁(1.1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=1760 all=19531 active=1104 piece=▁arbet\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=1780 all=19558 active=1131 piece=▁interest\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=1800 all=19654 active=1227 piece=alt\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=9 min_freq=6\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=1820 all=19739 active=1076 piece=äst\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=1840 all=19818 active=1155 piece=ever\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=1860 all=19881 active=1218 piece=▁His\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=1880 all=19921 active=1258 piece=▁sky\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=1900 all=20000 active=1337 piece=▁Dest\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=9 min_freq=6\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=1920 all=20013 active=1012 piece=▁sitt\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=1940 all=20029 active=1028 piece=▁total\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=1960 all=20023 active=1022 piece=▁reviderad\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=1980 all=20102 active=1101 piece=▁^\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=2000 all=20152 active=1151 piece=not\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=8 min_freq=6\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=2020 all=20233 active=1088 piece=▁ye\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=2040 all=20305 active=1160 piece=ites\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=2060 all=20353 active=1208 piece=▁fut\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=2080 all=20389 active=1244 piece=aktiv\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=2100 all=20424 active=1279 piece=▁2011\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=8 min_freq=5\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=2120 all=20436 active=1033 piece=▁poss\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=2140 all=20466 active=1063 piece=▁Krist\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=2160 all=20477 active=1074 piece=▁Yahweh\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=2180 all=20480 active=1077 piece=▁Kommission\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=2200 all=20540 active=1137 piece=Jes\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=7 min_freq=5\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=2220 all=20637 active=1122 piece=put\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=2240 all=20699 active=1184 piece=▁hö\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=2260 all=20743 active=1228 piece=ctor\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=2280 all=20816 active=1301 piece=utom\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=2300 all=20854 active=1339 piece=▁abs\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=7 min_freq=5\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=2320 all=20888 active=1075 piece=▁mag\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=2340 all=20942 active=1129 piece=ished\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=2360 all=20966 active=1153 piece=▁blir\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=2380 all=20979 active=1166 piece=▁tell\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=2400 all=21009 active=1196 piece=▁fader\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=7 min_freq=5\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=2420 all=21025 active=1067 piece=▁backup\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=2440 all=21023 active=1065 piece=▁minuter\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=2460 all=21034 active=1076 piece=?)\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=2480 all=21117 active=1159 piece=äv\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=2500 all=21158 active=1200 piece=agn\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=6 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=2520 all=21225 active=1121 piece=och\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=2540 all=21274 active=1170 piece=▁Om\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=2560 all=21306 active=1202 piece=Lidz\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=2580 all=21354 active=1250 piece=just\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=2600 all=21398 active=1294 piece=▁..\"\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=6 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=2620 all=21413 active=1085 piece=▁bea\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=2640 all=21453 active=1125 piece=▁pot\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=2660 all=21481 active=1153 piece=assad\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=2680 all=21519 active=1191 piece=▁(129\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=2700 all=21516 active=1188 piece=▁Lind\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=6 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=2720 all=21525 active=1081 piece=▁hitt\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=2740 all=21540 active=1096 piece=▁resp\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=2760 all=21553 active=1109 piece=Mastan\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=2780 all=21563 active=1119 piece=▁blasp\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=2800 all=21568 active=1124 piece=▁peace\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=6 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=2820 all=21574 active=1085 piece=ationer\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=2840 all=21579 active=1090 piece=▁called\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=2860 all=21584 active=1095 piece=ligheten\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=2880 all=21584 active=1095 piece=▁American\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=2900 all=21572 active=1083 piece=▁färgglada\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=6 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=2920 all=21591 active=1098 piece=OU\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=2940 all=21656 active=1163 piece=Men\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=2960 all=21713 active=1220 piece=esk\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=2980 all=21798 active=1305 piece=mån\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=3000 all=21866 active=1373 piece=▁25\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=5 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=3020 all=21873 active=1099 piece=▁ju\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=3040 all=21914 active=1140 piece=enom\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=3060 all=21972 active=1198 piece=sign\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=3080 all=22008 active=1234 piece=▁Gör\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=3100 all=22033 active=1259 piece=▁bus\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=5 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=3120 all=22057 active=1125 piece=▁law\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=3140 all=22069 active=1137 piece=centr\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=3160 all=22112 active=1180 piece=words\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=3180 all=22121 active=1189 piece=▁bröd\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=3200 all=22124 active=1192 piece=▁käns\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=5 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=3220 all=22127 active=1108 piece=▁stöd\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=3240 all=22146 active=1127 piece=ostnad\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=3260 all=22152 active=1133 piece=▁dator\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=3280 all=22155 active=1136 piece=▁spela\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=3300 all=22163 active=1144 piece=▁active\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=5 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=3320 all=22166 active=1112 piece=▁includ\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=3340 all=22162 active=1108 piece=▁within\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=3360 all=22159 active=1105 piece=▁picture\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=3380 all=22148 active=1094 piece=▁rättvisa\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=3400 all=22144 active=1090 piece=▁adjustable\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=5 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=3420 all=22146 active=1110 piece=4\"\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=3440 all=22164 active=1128 piece=FO\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=3460 all=22193 active=1157 piece=bl\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=3480 all=22237 active=1201 piece=▁>\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=3500 all=22254 active=1218 piece=Bir\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=3520 all=22262 active=1120 piece=TSC\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=3540 all=22299 active=1157 piece=ebr\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=3560 all=22359 active=1217 piece=lan\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=3580 all=22407 active=1265 piece=vet\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=3600 all=22433 active=1291 piece=▁91\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=3620 all=22448 active=1137 piece=▁mp\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=3640 all=22456 active=1145 piece=Read\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=3660 all=22485 active=1174 piece=edom\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=3680 all=22511 active=1200 piece=itle\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=3700 all=22555 active=1244 piece=oser\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=3720 all=22611 active=1181 piece=xter\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=3740 all=22609 active=1179 piece=▁Bab\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=3760 all=22615 active=1185 piece=▁MSD\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=3780 all=22628 active=1198 piece=▁WAV\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=3800 all=22639 active=1209 piece=▁eat\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=3820 all=22652 active=1145 piece=▁mob\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=3840 all=22668 active=1161 piece=▁why\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=3860 all=22686 active=1179 piece=blems\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=3880 all=22719 active=1212 piece=orter\n",
      "trainer_interface.cc(687) LOG(INFO) Saving model: m.model\n",
      "trainer_interface.cc(699) LOG(INFO) Saving vocabs: m.vocab\n"
     ]
    }
   ],
   "source": [
    "def text2codes(texts, sp):\n",
    "    codes = []\n",
    "    for text in texts:\n",
    "        text_l = text[0]\n",
    "        code = sp.encode_as_ids(text_l)\n",
    "        n_code = torch.tensor(code)\n",
    "        codes.append(n_code)\n",
    "\n",
    "    return codes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[\"!!TheM!Z!! hasn't added any friends yet!\"],\n",
       "  ['\" Memory / Summerday\" gouache/wood/butterfly 48x75 / 48x92cm 2006'],\n",
       "  ['\" child safety in Egypt \"\" harmfulness of the sun in Egypt on baby skin \"\" what medications the child in Egypt \"\" where on holiday with his family to Egypt \"\" pediatrician \"\" in which the child free hotels \"']],\n",
       " [['!!TheM!Z!! har inte lagt till några vänner ännu!'],\n",
       "  ['\"Hågkomst / Sommardag\" gouache/trä 48x75 /48x92cm2006'],\n",
       "  ['\" barnsäkerhet i Egypten \"\" skadlighet solen i Egypten på baby hud \"\" vilka mediciner barnet i Egypten \"\" där på semester med sin familj till Egypten \"\" barnläkare \"\" där barnet hotellsökningen \"']])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input_texts[:3], train_target_texts[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([   1,  311, 3644, 3937, 3980,  592,  611, 3958, 3896, 3256,  403, 1955,\n",
       "          526, 3937,    2]),\n",
       " tensor([   1,    8,   69,  173,  651,  439,   58,  174,  521, 2510, 3907,   52,\n",
       "           48,  447,   13, 3964, 2599, 3964, 3915, 3908, 1279, 2964,  390, 3960,\n",
       "         3954, 2461,  439,  390, 3960, 3954, 1787,  987,  321, 3953,    2]),\n",
       " tensor([   1,    8,  353,  398, 3828,   19, 3916,   37,  158,   75,  175, 3905,\n",
       "          520,  808,   44,   29, 2646,   37,  158,  153,   21, 2948, 3220,   75,\n",
       "          482, 1938,  663,   29,  353,  398,   37,  158,   75, 1312,  153, 2875,\n",
       "          202,  410, 3317,   61,  158,   75,   31,   35, 2968, 1347,  578,   75,\n",
       "           37,  382,   29,  353,  398,   14,  770, 1948,    8,    2])]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2codes(train_input_texts[:3], sp)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def codes2text(codes):\n",
    "    texts = []\n",
    "    for code in codes:\n",
    "        code_l = list(code)\n",
    "        for p in code_l:\n",
    "            texts.append(sp.id_to_piece(p.item()))\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>',\n",
       " '▁!!',\n",
       " 'TheM',\n",
       " '!',\n",
       " 'Z',\n",
       " '!!',\n",
       " '▁hasn',\n",
       " \"'\",\n",
       " 't',\n",
       " '▁added',\n",
       " '▁any',\n",
       " '▁friends',\n",
       " '▁yet',\n",
       " '!',\n",
       " '</s>',\n",
       " '<s>',\n",
       " '▁\"',\n",
       " '▁M',\n",
       " 'em',\n",
       " 'ory',\n",
       " '▁/',\n",
       " '▁S',\n",
       " 'um',\n",
       " 'mer',\n",
       " 'day',\n",
       " '\"',\n",
       " '▁g',\n",
       " 'ou',\n",
       " 'ac',\n",
       " 'he',\n",
       " '/',\n",
       " 'wood',\n",
       " '/',\n",
       " 'b',\n",
       " 'u',\n",
       " 'tter',\n",
       " 'fly',\n",
       " '▁4',\n",
       " '8',\n",
       " 'x',\n",
       " '75',\n",
       " '▁/',\n",
       " '▁4',\n",
       " '8',\n",
       " 'x',\n",
       " '92',\n",
       " 'cm',\n",
       " '▁200',\n",
       " '6',\n",
       " '</s>',\n",
       " '<s>',\n",
       " '▁\"',\n",
       " '▁ch',\n",
       " 'ild',\n",
       " '▁saf',\n",
       " 'et',\n",
       " 'y',\n",
       " '▁in',\n",
       " '▁Egypt',\n",
       " '▁\"\"',\n",
       " '▁har',\n",
       " 'm',\n",
       " 'ful',\n",
       " 'ness',\n",
       " '▁of',\n",
       " '▁the',\n",
       " '▁sun',\n",
       " '▁in',\n",
       " '▁Egypt',\n",
       " '▁on',\n",
       " '▁b',\n",
       " 'aby',\n",
       " '▁skin',\n",
       " '▁\"\"',\n",
       " '▁what',\n",
       " '▁medic',\n",
       " 'ations',\n",
       " '▁the',\n",
       " '▁ch',\n",
       " 'ild',\n",
       " '▁in',\n",
       " '▁Egypt',\n",
       " '▁\"\"',\n",
       " '▁where',\n",
       " '▁on',\n",
       " '▁holiday',\n",
       " '▁with',\n",
       " '▁his',\n",
       " '▁family',\n",
       " '▁to',\n",
       " '▁Egypt',\n",
       " '▁\"\"',\n",
       " '▁p',\n",
       " 'ed',\n",
       " 'iat',\n",
       " 'ric',\n",
       " 'ian',\n",
       " '▁\"\"',\n",
       " '▁in',\n",
       " '▁which',\n",
       " '▁the',\n",
       " '▁ch',\n",
       " 'ild',\n",
       " '▁f',\n",
       " 'ree',\n",
       " '▁hotels',\n",
       " '▁\"',\n",
       " '</s>']"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codes2text(text2codes(train_input_texts[:3], sp)[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self,\n",
    "                 emb_size: int,\n",
    "                 dropout: float,\n",
    "                 maxlen: int = 5000):\n",
    "        super().__init__()\n",
    "        den = torch.exp(- torch.arange(0, emb_size, 2)\n",
    "                        * math.log(10000) / emb_size)\n",
    "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
    "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
    "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
    "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
    "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer('pos_embedding', pos_embedding)\n",
    "        self.emb_size = emb_size\n",
    "\n",
    "    def forward(self, token_embedding: Tensor):\n",
    "        return self.dropout(token_embedding * math.sqrt(self.emb_size)\n",
    "                            + self.pos_embedding[:token_embedding.size(0), :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "pe = PositionalEncoding(10, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(1, 5, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000, 1.1111, 0.0000, 1.1111, 0.0000, 1.1111, 0.0000, 1.1111,\n",
       "          0.0000, 0.0000],\n",
       "         [0.0000, 1.1111, 0.0000, 1.1111, 0.0000, 1.1111, 0.0000, 1.1111,\n",
       "          0.0000, 1.1111],\n",
       "         [0.0000, 1.1111, 0.0000, 1.1111, 0.0000, 1.1111, 0.0000, 1.1111,\n",
       "          0.0000, 1.1111],\n",
       "         [0.0000, 1.1111, 0.0000, 1.1111, 0.0000, 0.0000, 0.0000, 1.1111,\n",
       "          0.0000, 1.1111],\n",
       "         [0.0000, 1.1111, 0.0000, 1.1111, 0.0000, 1.1111, 0.0000, 1.1111,\n",
       "          0.0000, 1.1111]]])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pe(torch.zeros(1, 5, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Seq2Seq Network\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# from torch import Tensor\n",
    "# from torch.nn import TransformerEncoder, TransformerDecoder, TransformerEncoderLayer, TransformerDecoderLayer\n",
    "\n",
    "# class Seq2SeqTransformer(nn.Module):\n",
    "#     def __init__(self,\n",
    "#                  num_encoder_layers: int,\n",
    "#                  num_decoder_layers: int,\n",
    "#                  emb_size: int,\n",
    "#                  nhead: int,\n",
    "#                  vocab_size: int,\n",
    "#                  dim_feedforward: int = 512,\n",
    "#                  dropout: float = 0.1):\n",
    "#         super().__init__()\n",
    "#         encoder_layers = TransformerEncoderLayer(emb_size, nhead, dim_feedforward, dropout)\n",
    "#         decoder_layers = TransformerDecoderLayer(emb_size, nhead, dim_feedforward, dropout)\n",
    "#         self.transformer_encoder = TransformerEncoder(encoder_layers, num_encoder_layers)\n",
    "#         self.transformer_decoder = TransformerDecoder(decoder_layers, num_decoder_layers)\n",
    "\n",
    "#         self.emb_size = emb_size\n",
    "#         self.embedding = nn.Embedding(\n",
    "#             vocab_size, emb_size, padding_idx=3)\n",
    "#         self.positional_encoding = PositionalEncoding(\n",
    "#             emb_size, dropout=dropout)\n",
    "#         self.generator = nn.Linear(emb_size, vocab_size, bias=False)\n",
    "#         self.generator.weight = self.embedding.weight\n",
    "\n",
    "#     def forward(self,\n",
    "#                 src: Tensor,\n",
    "#                 trg: Tensor,\n",
    "#                 src_mask: Tensor,\n",
    "#                 tgt_mask: Tensor,\n",
    "#                 src_padding_mask: Tensor,\n",
    "#                 tgt_padding_mask: Tensor,\n",
    "#                 memory_key_padding_mask: Tensor):\n",
    "#         src_emb = self.positional_encoding(self.embedding(src))\n",
    "#         tgt_emb = self.positional_encoding(self.embedding(trg))\n",
    "        \n",
    "#         memory = self.transformer_encoder(src_emb, src_mask, src_padding_mask)\n",
    "#         outs = self.transformer_decoder(tgt_emb, memory, tgt_mask, None,\n",
    "#                                         tgt_padding_mask, memory_key_padding_mask)\n",
    "#         return self.generator(outs)\n",
    "\n",
    "#     def encode(self, src: Tensor, src_mask: Tensor):\n",
    "#         return self.transformer_encoder(self.positional_encoding(\n",
    "#             self.embedding(src)), src_mask)\n",
    "\n",
    "#     def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n",
    "#         return self.transformer_decoder(self.positional_encoding(\n",
    "#             self.embedding(tgt)), memory,\n",
    "#             tgt_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seq2Seq Network\n",
    "class Seq2SeqTransformer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_encoder_layers: int,\n",
    "                 num_decoder_layers: int,\n",
    "                 emb_size: int,\n",
    "                 nhead: int,\n",
    "                 vocab_size: int,\n",
    "                 dim_feedforward: int = 512,\n",
    "                 dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.transformer = Transformer(d_model=emb_size,\n",
    "                                       nhead=nhead,\n",
    "                                       num_encoder_layers=num_encoder_layers,\n",
    "                                       num_decoder_layers=num_decoder_layers,\n",
    "                                       dim_feedforward=dim_feedforward,\n",
    "                                       dropout=dropout)\n",
    "\n",
    "        self.emb_size = emb_size\n",
    "        # Same source and target embs Sect. 3.4\n",
    "        self.embedding = nn.Embedding(\n",
    "            vocab_size, emb_size, padding_idx=3)\n",
    "        self.positional_encoding = PositionalEncoding(\n",
    "            emb_size, dropout=dropout)\n",
    "        # Bias to be compatible with embeddings\n",
    "        self.generator = nn.Linear(emb_size, vocab_size, bias=False)\n",
    "        self.generator.weight = self.embedding.weight  # Shared weights Sect. 3.4\n",
    "\n",
    "    def forward(self,\n",
    "                src: Tensor,\n",
    "                trg: Tensor,\n",
    "                src_mask: Tensor,\n",
    "                tgt_mask: Tensor,\n",
    "                src_padding_mask: Tensor,\n",
    "                tgt_padding_mask: Tensor,\n",
    "                memory_key_padding_mask: Tensor):\n",
    "        src_emb = self.positional_encoding(self.embedding(src))\n",
    "        tgt_emb = self.positional_encoding(self.embedding(trg))\n",
    "        outs = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, None,\n",
    "                                src_padding_mask, tgt_padding_mask, memory_key_padding_mask)\n",
    "        return self.generator(outs)\n",
    "\n",
    "    def encode(self, src: Tensor, src_mask: Tensor):\n",
    "        return self.transformer.encoder(self.positional_encoding(\n",
    "            self.embedding(src)), src_mask)\n",
    "\n",
    "    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n",
    "        return self.transformer.decoder(self.positional_encoding(\n",
    "            self.embedding(tgt)), memory,\n",
    "            tgt_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_square_subsequent_mask(sz):\n",
    "    mask = (torch.triu(torch.ones((sz, sz), device=DEVICE)) == 1).transpose(0, 1)\n",
    "    mask = mask.float().masked_fill(mask == 0, float(\n",
    "        '-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_square_subsequent_mask(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(src, tgt):\n",
    "    src_seq_len = src.shape[0]\n",
    "    tgt_seq_len = tgt.shape[0]\n",
    "\n",
    "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
    "    src_mask = torch.zeros((src_seq_len, src_seq_len),\n",
    "                           device=DEVICE).type(torch.bool)\n",
    "\n",
    "    src_padding_mask = (src == 3).transpose(0, 1)\n",
    "    tgt_padding_mask = (tgt == 3).transpose(0, 1).type(torch.float32)\n",
    "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = pad_sequence(text2codes(\n",
    "    train_input_texts[:3], sp), padding_value=3)\n",
    "tgt = pad_sequence(text2codes(\n",
    "    train_target_texts[:3], sp), padding_value=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[\"!!TheM!Z!! hasn't added any friends yet!\"],\n",
       "  ['\" Memory / Summerday\" gouache/wood/butterfly 48x75 / 48x92cm 2006'],\n",
       "  ['\" child safety in Egypt \"\" harmfulness of the sun in Egypt on baby skin \"\" what medications the child in Egypt \"\" where on holiday with his family to Egypt \"\" pediatrician \"\" in which the child free hotels \"']],\n",
       " [['!!TheM!Z!! har inte lagt till några vänner ännu!'],\n",
       "  ['\"Hågkomst / Sommardag\" gouache/trä 48x75 /48x92cm2006'],\n",
       "  ['\" barnsäkerhet i Egypten \"\" skadlighet solen i Egypten på baby hud \"\" vilka mediciner barnet i Egypten \"\" där på semester med sin familj till Egypten \"\" barnläkare \"\" där barnet hotellsökningen \"']])"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input_texts[:3], train_target_texts[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         ...,\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False]]),\n",
       " tensor([[0., -inf, -inf,  ..., -inf, -inf, -inf],\n",
       "         [0., 0., -inf,  ..., -inf, -inf, -inf],\n",
       "         [0., 0., 0.,  ..., -inf, -inf, -inf],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., -inf, -inf],\n",
       "         [0., 0., 0.,  ..., 0., 0., -inf],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " tensor([[False, False, False, False, False, False, False, False, False, False,\n",
       "          False, False, False, False, False,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True],\n",
       "         [False, False, False, False, False, False, False, False, False, False,\n",
       "          False, False, False, False, False, False, False, False, False, False,\n",
       "          False, False, False, False, False, False, False, False, False, False,\n",
       "          False, False, False, False, False,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True],\n",
       "         [False, False, False, False, False, False, False, False, False, False,\n",
       "          False, False, False, False, False, False, False, False, False, False,\n",
       "          False, False, False, False, False, False, False, False, False, False,\n",
       "          False, False, False, False, False, False, False, False, False, False,\n",
       "          False, False, False, False, False, False, False, False, False, False,\n",
       "          False, False, False, False, False, False, False, False]]),\n",
       " tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]))"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_mask(src, tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 4000 #max(token2idx.values()) + 1  # or len(token2idx)\n",
    "EMB_SIZE = 512\n",
    "NHEAD = 8\n",
    "FFN_HID_DIM = 512\n",
    "BATCH_SIZE = 128\n",
    "NUM_ENCODER_LAYERS = 6\n",
    "NUM_DECODER_LAYERS = 6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rate(step, model_size, factor, warmup):\n",
    "    \"\"\"\n",
    "    we have to default the step to 1 for LambdaLR function\n",
    "    to avoid zero raising to negative power.\n",
    "    \"\"\"\n",
    "    if step == 0:\n",
    "        step = 1\n",
    "    return factor * (\n",
    "        model_size ** (-0.5) * min(step ** (-0.5), step * warmup ** (-1.5))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,\n",
    "                                 NHEAD, VOCAB_SIZE, FFN_HID_DIM)\n",
    "\n",
    "for p in transformer.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "\n",
    "transformer = transformer.to(DEVICE)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=3)\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "            transformer.parameters(), lr=0.5, betas=(0.9, 0.98), eps=1e-9\n",
    "        )\n",
    "lr_scheduler = LambdaLR(\n",
    "        optimizer=optimizer,\n",
    "        lr_lambda=lambda step: rate(\n",
    "            step, model_size=transformer.emb_size, factor=1.0, warmup=4000\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairDataset(Dataset):\n",
    "    def __init__(self, input_texts, target_texts, token2idx):\n",
    "        self.input_texts = input_texts\n",
    "        self.target_texts = target_texts\n",
    "        self.token2idx = token2idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        src_batch = text2codes([input_texts[idx]], self.token2idx)\n",
    "        tgt_batch = text2codes([target_texts[idx]], self.token2idx)\n",
    "\n",
    "        return src_batch[0], tgt_batch[0]\n",
    "\n",
    "    def collate(self, batch):\n",
    "        src_batch, tgt_batch = list(zip(*batch))\n",
    "        src_batch = pad_sequence(src_batch, padding_value=3)\n",
    "        tgt_batch = pad_sequence(tgt_batch, padding_value=3)\n",
    "\n",
    "        return src_batch, tgt_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PairDataset(train_input_texts, train_target_texts, sp)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32,\n",
    "                              shuffle=True, collate_fn=train_dataset.collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = PairDataset(val_input_texts, val_target_texts, sp)\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset, batch_size=32, collate_fn=val_dataset.collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainState:\n",
    "    \"\"\"Track number of steps, examples, and tokens processed\"\"\"\n",
    "\n",
    "    step: int = 0  # Steps in the current epoch\n",
    "    accum_step: int = 0  # Number of gradient accumulation steps\n",
    "    samples: int = 0  # total # of examples used\n",
    "    tokens: int = 0  # total # of tokens processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, optimizer, dataloader, scheduler, accum_iter=1, train_state=TrainState()):\n",
    "    model.train()\n",
    "    losses = 0\n",
    "    sent_cnt = 0\n",
    "    correct, total = 0, 0\n",
    "    for src_batch, tgt_batch in tqdm(dataloader):\n",
    "        src = src_batch.to(DEVICE)\n",
    "        tgt = tgt_batch.to(DEVICE)\n",
    "\n",
    "        tgt_input = tgt[:-1, :]\n",
    "\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(\n",
    "            src, tgt_input)\n",
    "\n",
    "        logits = model(src,\n",
    "                       tgt_input,\n",
    "                       src_mask,\n",
    "                       tgt_mask,\n",
    "                       src_padding_mask,\n",
    "                       tgt_padding_mask,\n",
    "                       src_padding_mask)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        tgt_out = tgt[1:, :]\n",
    "        loss = loss_fn(\n",
    "            logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        losses += loss.item()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            sent_cnt += tgt_out.size()[-1]\n",
    "\n",
    "            total += torch.numel(tgt_input)\n",
    "            _, char_pred = torch.max(logits, -1)\n",
    "            correct += (char_pred == tgt_out).sum().item()\n",
    "\n",
    "    return losses / sent_cnt, correct / total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    losses = 0\n",
    "    sent_cnt = 0\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    for src_batch, tgt_batch in dataloader:\n",
    "        src = src_batch.to(DEVICE)\n",
    "        tgt = tgt_batch.to(DEVICE)\n",
    "\n",
    "        tgt_input = tgt[:-1, :]\n",
    "\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(\n",
    "            src, tgt_input)\n",
    "\n",
    "        logits = model(src, tgt_input, src_mask, tgt_mask,\n",
    "                       src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
    "\n",
    "        tgt_out = tgt[1:, :]\n",
    "        loss = loss_fn(\n",
    "            logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "        losses += loss.item()\n",
    "        sent_cnt += tgt_out.size()[-1]\n",
    "\n",
    "        total += torch.numel(tgt_input)\n",
    "        _, char_pred = torch.max(logits, -1)\n",
    "        correct += (char_pred == tgt_out).sum().item()\n",
    "\n",
    "    return losses / sent_cnt, correct / total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:42<00:00,  1.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train loss: 0.262, Val loss: 0.292, Train acc.: 0.008, Val acc.: 0.001, Epoch time = 42.894s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:41<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Train loss: 0.259, Val loss: 0.287, Train acc.: 0.002, Val acc.: 0.001, Epoch time = 41.186s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:39<00:00,  1.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Train loss: 0.255, Val loss: 0.280, Train acc.: 0.003, Val acc.: 0.009, Epoch time = 39.952s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:40<00:00,  1.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Train loss: 0.250, Val loss: 0.275, Train acc.: 0.009, Val acc.: 0.011, Epoch time = 40.963s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:38<00:00,  1.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Train loss: 0.245, Val loss: 0.270, Train acc.: 0.011, Val acc.: 0.012, Epoch time = 38.248s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:40<00:00,  1.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Train loss: 0.241, Val loss: 0.266, Train acc.: 0.011, Val acc.: 0.013, Epoch time = 40.929s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 5/25 [00:08<00:32,  1.62s/it]\n",
      "[E thread_pool.cpp:110] Exception in thread pool task: mutex lock failed: Invalid argument\n",
      "[E thread_pool.cpp:110] Exception in thread pool task: mutex lock failed: Invalid argument\n",
      "[E thread_pool.cpp:110] Exception in thread pool task: mutex lock failed: Invalid argument\n",
      "[E thread_pool.cpp:110] Exception in thread pool task: mutex lock failed: Invalid argument\n",
      "[E thread_pool.cpp:110] Exception in thread pool task: mutex lock failed: Invalid argument\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[240], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, NUM_EPOCHS \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m      9\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m timer()\n\u001b[0;32m---> 10\u001b[0m     train_loss, train_acc \u001b[38;5;241m=\u001b[39m train_epoch(\n\u001b[1;32m     11\u001b[0m         transformer, optimizer, train_dataloader, lr_scheduler)\n\u001b[1;32m     12\u001b[0m     train_losses \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [train_loss]\n\u001b[1;32m     13\u001b[0m     train_accs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [train_acc]\n",
      "Cell \u001b[0;32mIn[238], line 15\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, optimizer, dataloader, scheduler, accum_iter, train_state)\u001b[0m\n\u001b[1;32m     10\u001b[0m tgt_input \u001b[38;5;241m=\u001b[39m tgt[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]\n\u001b[1;32m     12\u001b[0m src_mask, tgt_mask, src_padding_mask, tgt_padding_mask \u001b[38;5;241m=\u001b[39m create_mask(\n\u001b[1;32m     13\u001b[0m     src, tgt_input)\n\u001b[0;32m---> 15\u001b[0m logits \u001b[38;5;241m=\u001b[39m model(src,\n\u001b[1;32m     16\u001b[0m                tgt_input,\n\u001b[1;32m     17\u001b[0m                src_mask,\n\u001b[1;32m     18\u001b[0m                tgt_mask,\n\u001b[1;32m     19\u001b[0m                src_padding_mask,\n\u001b[1;32m     20\u001b[0m                tgt_padding_mask,\n\u001b[1;32m     21\u001b[0m                src_padding_mask)\n\u001b[1;32m     23\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     25\u001b[0m tgt_out \u001b[38;5;241m=\u001b[39m tgt[\u001b[38;5;241m1\u001b[39m:, :]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[211], line 42\u001b[0m, in \u001b[0;36mSeq2SeqTransformer.forward\u001b[0;34m(self, src, trg, src_mask, tgt_mask, src_padding_mask, tgt_padding_mask, memory_key_padding_mask)\u001b[0m\n\u001b[1;32m     39\u001b[0m tgt_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositional_encoding(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(trg))\n\u001b[1;32m     41\u001b[0m memory \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer_encoder(src_emb, src_mask, src_padding_mask)\n\u001b[0;32m---> 42\u001b[0m outs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer_decoder(tgt_emb, memory, tgt_mask, \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     43\u001b[0m                                 tgt_padding_mask, memory_key_padding_mask)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerator(outs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/transformer.py:460\u001b[0m, in \u001b[0;36mTransformerDecoder.forward\u001b[0;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask, tgt_is_causal, memory_is_causal)\u001b[0m\n\u001b[1;32m    457\u001b[0m tgt_is_causal \u001b[38;5;241m=\u001b[39m _detect_is_causal_mask(tgt_mask, tgt_is_causal, seq_len)\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m--> 460\u001b[0m     output \u001b[38;5;241m=\u001b[39m mod(output, memory, tgt_mask\u001b[38;5;241m=\u001b[39mtgt_mask,\n\u001b[1;32m    461\u001b[0m                  memory_mask\u001b[38;5;241m=\u001b[39mmemory_mask,\n\u001b[1;32m    462\u001b[0m                  tgt_key_padding_mask\u001b[38;5;241m=\u001b[39mtgt_key_padding_mask,\n\u001b[1;32m    463\u001b[0m                  memory_key_padding_mask\u001b[38;5;241m=\u001b[39mmemory_key_padding_mask,\n\u001b[1;32m    464\u001b[0m                  tgt_is_causal\u001b[38;5;241m=\u001b[39mtgt_is_causal,\n\u001b[1;32m    465\u001b[0m                  memory_is_causal\u001b[38;5;241m=\u001b[39mmemory_is_causal)\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    468\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(output)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/transformer.py:846\u001b[0m, in \u001b[0;36mTransformerDecoderLayer.forward\u001b[0;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask, tgt_is_causal, memory_is_causal)\u001b[0m\n\u001b[1;32m    844\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm3(x))\n\u001b[1;32m    845\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 846\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sa_block(x, tgt_mask, tgt_key_padding_mask, tgt_is_causal))\n\u001b[1;32m    847\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mha_block(x, memory, memory_mask, memory_key_padding_mask, memory_is_causal))\n\u001b[1;32m    848\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm3(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(x))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/transformer.py:855\u001b[0m, in \u001b[0;36mTransformerDecoderLayer._sa_block\u001b[0;34m(self, x, attn_mask, key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    853\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sa_block\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor,\n\u001b[1;32m    854\u001b[0m               attn_mask: Optional[Tensor], key_padding_mask: Optional[Tensor], is_causal: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 855\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn(x, x, x,\n\u001b[1;32m    856\u001b[0m                        attn_mask\u001b[38;5;241m=\u001b[39mattn_mask,\n\u001b[1;32m    857\u001b[0m                        key_padding_mask\u001b[38;5;241m=\u001b[39mkey_padding_mask,\n\u001b[1;32m    858\u001b[0m                        is_causal\u001b[38;5;241m=\u001b[39mis_causal,\n\u001b[1;32m    859\u001b[0m                        need_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout1(x)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/activation.py:1241\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   1227\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmulti_head_attention_forward(\n\u001b[1;32m   1228\u001b[0m         query, key, value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_dim, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads,\n\u001b[1;32m   1229\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_weight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_bias,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1238\u001b[0m         average_attn_weights\u001b[38;5;241m=\u001b[39maverage_attn_weights,\n\u001b[1;32m   1239\u001b[0m         is_causal\u001b[38;5;241m=\u001b[39mis_causal)\n\u001b[1;32m   1240\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1241\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmulti_head_attention_forward(\n\u001b[1;32m   1242\u001b[0m         query, key, value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_dim, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads,\n\u001b[1;32m   1243\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_weight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_bias,\n\u001b[1;32m   1244\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias_k, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias_v, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_zero_attn,\n\u001b[1;32m   1245\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_proj\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_proj\u001b[38;5;241m.\u001b[39mbias,\n\u001b[1;32m   1246\u001b[0m         training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining,\n\u001b[1;32m   1247\u001b[0m         key_padding_mask\u001b[38;5;241m=\u001b[39mkey_padding_mask,\n\u001b[1;32m   1248\u001b[0m         need_weights\u001b[38;5;241m=\u001b[39mneed_weights,\n\u001b[1;32m   1249\u001b[0m         attn_mask\u001b[38;5;241m=\u001b[39mattn_mask,\n\u001b[1;32m   1250\u001b[0m         average_attn_weights\u001b[38;5;241m=\u001b[39maverage_attn_weights,\n\u001b[1;32m   1251\u001b[0m         is_causal\u001b[38;5;241m=\u001b[39mis_causal)\n\u001b[1;32m   1252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first \u001b[38;5;129;01mand\u001b[39;00m is_batched:\n\u001b[1;32m   1253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m), attn_output_weights\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/functional.py:5300\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   5298\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m use_separate_proj_weight:\n\u001b[1;32m   5299\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m in_proj_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_separate_proj_weight is False but in_proj_weight is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 5300\u001b[0m     q, k, v \u001b[38;5;241m=\u001b[39m _in_projection_packed(query, key, value, in_proj_weight, in_proj_bias)\n\u001b[1;32m   5301\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   5302\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m q_proj_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_separate_proj_weight is True but q_proj_weight is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/functional.py:4826\u001b[0m, in \u001b[0;36m_in_projection_packed\u001b[0;34m(q, k, v, w, b)\u001b[0m\n\u001b[1;32m   4824\u001b[0m     proj \u001b[38;5;241m=\u001b[39m linear(q, w, b)\n\u001b[1;32m   4825\u001b[0m     \u001b[38;5;66;03m# reshape to 3, E and not E, 3 is deliberate for better memory coalescing and keeping same order as chunk()\u001b[39;00m\n\u001b[0;32m-> 4826\u001b[0m     proj \u001b[38;5;241m=\u001b[39m proj\u001b[38;5;241m.\u001b[39munflatten(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, (\u001b[38;5;241m3\u001b[39m, E))\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[1;32m   4827\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m proj[\u001b[38;5;241m0\u001b[39m], proj[\u001b[38;5;241m1\u001b[39m], proj[\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m   4828\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4829\u001b[0m     \u001b[38;5;66;03m# encoder-decoder attention\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "NUM_EPOCHS = 15\n",
    "train_losses = []\n",
    "train_accs = []\n",
    "val_losses = []\n",
    "val_accs = []\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    start_time = timer()\n",
    "    train_loss, train_acc = train_epoch(\n",
    "        transformer, optimizer, train_dataloader, lr_scheduler)\n",
    "    train_losses += [train_loss]\n",
    "    train_accs += [train_acc]\n",
    "    end_time = timer()\n",
    "    val_loss, val_acc = evaluate(transformer, val_dataloader)\n",
    "    val_losses += [val_loss]\n",
    "    val_accs += [val_acc]\n",
    "    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, Train acc.: {train_acc:.3f}, Val acc.: {val_acc:.3f}, Epoch time = {(end_time - start_time):.3f}s\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = range(NUM_EPOCHS)\n",
    "\n",
    "plt.plot(epochs, train_losses, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_losses, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochs, train_accs, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_accs, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to generate output sequence using greedy algorithm\n",
    "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
    "    src = src.to(DEVICE)\n",
    "    src_mask = src_mask.to(DEVICE)\n",
    "\n",
    "    memory = model.encode(src, src_mask)\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
    "    # print(ys)\n",
    "    for i in range(max_len-1):\n",
    "        memory = memory.to(DEVICE)\n",
    "        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n",
    "                    .type(torch.bool)).to(DEVICE)\n",
    "        out = model.decode(ys, memory, tgt_mask)\n",
    "        out = out.transpose(0, 1)\n",
    "        prob = model.generator(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim=1)\n",
    "        next_word = next_word.item()\n",
    "\n",
    "        ys = torch.cat([ys,\n",
    "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
    "        # print(ys) # Remove the comment to understand the loop\n",
    "        if next_word == 2:\n",
    "            break\n",
    "    return ys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  1],\n",
       "        [138],\n",
       "        [  2]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2codes(['Go!'], sp)[0].view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actual function to translate input sentence into target language\n",
    "def translate(model: torch.nn.Module, src_sentence: str):\n",
    "    model.eval()\n",
    "    src = text2codes([src_sentence], sp)[0].view(-1, 1)\n",
    "    print(\"SRC: \", src)\n",
    "    num_tokens = src.shape[0]\n",
    "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
    "    tgt_tokens = greedy_decode(\n",
    "        model, src, src_mask, max_len=num_tokens + 20, start_symbol=1).flatten()\n",
    "    print(\"Targ: \", tgt_tokens)\n",
    "    tgt_chars_specials = codes2text([tgt_tokens])\n",
    "    tgt_chars = []\n",
    "    for char in tgt_chars_specials:\n",
    "        if char != '<s>' and char != '<\\s>':\n",
    "            tgt_chars += [char]\n",
    "    tgt_chars = ''.join(tgt_chars)\n",
    "    return tgt_chars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRC:  tensor([[ 1],\n",
      "        [74],\n",
      "        [ 2]])\n",
      "Targ:  tensor([  1,   8,   8, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209,\n",
      "        209, 209,   2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'▁\"▁\"▁jag▁jag▁jag▁jag▁jag▁jag▁jag▁jag▁jag▁jag▁jag▁jag▁jag</s>'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt_sent = translate(transformer, 'I drink water every day')\n",
    "tgt_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRC:  tensor([[ 1],\n",
      "        [85],\n",
      "        [ 2]])\n",
      "Targ:  tensor([1, 8, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'▁\"</s>'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt = translate(transformer, \"The house at the end of my street is red\")\n",
    "tgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"kt reara reara reara reara reara reara reara reara re\n"
     ]
    }
   ],
   "source": [
    "print(sp.decode_ids([  1,   8, 129, 144, 254, 144, 254, 144, 254, 144, 254, 144, 254, 144,\n",
    "        254, 144, 254, 144, 254, 144,   2]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
